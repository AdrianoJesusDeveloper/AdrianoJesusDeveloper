{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdrianoJesusDeveloper/AdrianoJesusDeveloper/blob/main/convertendo_texto_em__xlsx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsZe93Fi0cPc"
      },
      "source": [
        "#VERSÃO DA LINGUAGEM PYTHON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFwS60YG0iWl",
        "outputId": "bccb670b-c18f-46a1-84f2-54298ead131d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "A versão em uso é 3.10.12\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "%pip install openpyxl #https://openpyxl.readthedocs.io/en/stable/ acesse pa entender a biblioteca  remova o '#' para instalar  apos instalar comnte novamente\n",
        "%pip install xlsxwriter #https://pypi.org/project/XlsxWriter/ acesse para entender a biblioteca remova o '#' para instalar  apos instalar comnte novamente\n",
        "print(f'A versão em uso é {python_version()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS668Xmi1Sj7"
      },
      "source": [
        "#importando a bibliotecas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gObE3uP1qA9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np #https://numpy.org/\n",
        "import pandas as pd #https://pandas.pydata.org/\n",
        "import datetime as dt #https://docs.python.org/3/library/datetime.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klK4Uj-MelhJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q56aOajR2v0q"
      },
      "source": [
        "Função para extrair Informações  com base em padrões regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iT_Db3T-28MZ"
      },
      "outputs": [],
      "source": [
        "#Definindo a variável content com o conteúdo do seu arquivo\n",
        "with open('01-2024.txt', 'r', encoding='utf-8') as file:\n",
        "    content = file.read() # lendo o aquivo de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sry3uMW5sESZ"
      },
      "outputs": [],
      "source": [
        "# Função para extrair informações com base em padrões regex\n",
        "def extract_info(section, pattern):\n",
        "  match = re.search(pattern, section)\n",
        "  return match.group(1).strip() if match else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Olbr8Etj6XyS"
      },
      "outputs": [],
      "source": [
        "# Dividindo o conteúdo em seções com base no 'Empregador: ' para tratar várias seções separadamente\n",
        "sections = content.split('Empregador: ')[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmvgS16J7qvS"
      },
      "outputs": [],
      "source": [
        "# Processando cada seção em um DataFrame\n",
        "dataframes = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20Wwn5ok7va8"
      },
      "outputs": [],
      "source": [
        "for section in sections:\n",
        "    lines = section.split('\\n')\n",
        "\n",
        "    # Extraindo informações comuns da seção\n",
        "    empregador_info = 'Empregador: ' + extract_info(section, r'(.+?) Cartão de ponto')\n",
        "    cnpj = extract_info(section, r'CNPJ: (.+?)\\s')\n",
        "    endereco = extract_info(section, r'End: (.+?) Competência')\n",
        "\n",
        "    # Verificando se a linha da competência existe\n",
        "    competencia_line = lines[3] if len(lines) > 3 else ''\n",
        "    competencia = competencia_line.split(': ')[1] if ':' in competencia_line else None\n",
        "\n",
        "    unidade = extract_info(section, r'Unidade: (.+?) Data de admissão')\n",
        "    admissao = extract_info(section, r'Data de admissão (.+)')\n",
        "    funcionario_id_nome = extract_info(section, r'Funcionário: (\\d+ - .+) Cargo:')\n",
        "    cargo = extract_info(section, r'Cargo: (.+)')\n",
        "\n",
        "    if funcionario_id_nome:\n",
        "        funcionario_id, funcionario_nome = funcionario_id_nome.split(' - ')\n",
        "    else:\n",
        "        funcionario_id, funcionario_nome = None, None\n",
        "\n",
        "    # Extraindo registros\n",
        "    records_start = section.find('Registros Crédito Débitos Faltas e Atrasos') + len('Registros Crédito Débitos Faltas e Atrasos') + 1\n",
        "    records_end = section.find('Crédito', records_start)\n",
        "    records = section[records_start:records_end].strip().split('\\n')\n",
        "\n",
        "    # Analisando registros em uma lista de dicionários\n",
        "    data = []\n",
        "    for record in records:\n",
        "        parts = record.split()\n",
        "        if len(parts) < 14:  # Ignorar registros com elementos ausentes\n",
        "            continue\n",
        "        date = parts[0]\n",
        "        work_times = ' '.join(parts[1:6])\n",
        "        work_type = ' '.join(parts[6:-6])\n",
        "        credit = parts[-6]\n",
        "        debit = parts[-5]\n",
        "        faltas_atrasos = parts[-4]\n",
        "        data.append({\n",
        "            'Empregador': empregador_info,\n",
        "            'CNPJ': cnpj,\n",
        "            'Endereço': endereco,\n",
        "            'Competência': competencia,\n",
        "            'Unidade': unidade,\n",
        "            'Data de admissão': admissao,\n",
        "            'Funcionário ID': funcionario_id,\n",
        "            'Funcionário Nome': funcionario_nome,\n",
        "            'Cargo': cargo,\n",
        "            'Data': date,\n",
        "            'Horários de Trabalho': work_times,\n",
        "            'Tipo de Trabalho': work_type,\n",
        "            'Crédito': credit,\n",
        "            'Débito': debit,\n",
        "            'Faltas e Atrasos': faltas_atrasos\n",
        "        })\n",
        "\n",
        "    # Convertendo a lista de dicionários em um DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    dataframes.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBQBFvoaRn1Y"
      },
      "source": [
        "\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJtGWwbO9D-M"
      },
      "outputs": [],
      "source": [
        "# Combinando todos os DataFrames em um\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ3l4T61Bxkx"
      },
      "outputs": [],
      "source": [
        "#dividindo a coluna Horários  de Trabalho em tres colunas\n",
        "combined_df[['Sáída', 'Saida Almoço', 'Retorno Almoço']] = combined_df['Horários de Trabalho'].str.split('-', expand=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEqXWDY-Dq4V"
      },
      "outputs": [],
      "source": [
        "# Removendo o caractere \"-\" no início de cada linha na coluna 'Tipo de Trabalho'\n",
        "combined_df['Tipo de Trabalho'] = combined_df['Tipo de Trabalho'].str.lstrip('-')\n",
        "combined_df['Tipo de Trabalho'] = combined_df['Tipo de Trabalho'].str.replace('/', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaYSMw_yg_z3"
      },
      "outputs": [],
      "source": [
        "# Dividindo a acoluna Tipo de Trabalho em duas colunas\n",
        "combined_df[['Entrada', 'Tipo de Trabalho']] = combined_df['Tipo de Trabalho'].str.split(' ', n=1, expand=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair os horários da coluna 'Tipo de Trabalho'\n",
        "combined_df['Entrada'] = combined_df['Tipo de Trabalho'].str.extract(r'(\\d{2}:\\d{2})')"
      ],
      "metadata": {
        "id": "H4xs3cL5VDXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "emNtjXQ9WiXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RfubPPWDWiWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvXORjpYSSO3"
      },
      "outputs": [],
      "source": [
        "# Formatando os dados da tabela do tipo entrada para O TIPO HORAS\n",
        "#combined_df['Entrada'] = pd.to_datetime(combined_df['Entrada'], format='%H:%M', errors='coerce').dt.time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.drop(columns=['Horários de Trabalho', 'Tipo de Trabalho'], inplace=True)\n"
      ],
      "metadata": {
        "id": "Ds5andiiXvq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrXgVYrF2nI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc106262-1513-470a-c782-323819e1089f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo Excel salvo em: /content/01-2024.xlsx\n"
          ]
        }
      ],
      "source": [
        "# #Salvando as alterações e convertendo em um arquivo\n",
        "output_file_path = '/content/01-2024.xlsx'\n",
        "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
        "    combined_df.to_excel(writer, index=False, sheet_name='Data')\n",
        "    worksheet = writer.sheets['Data']\n",
        "    for col_num, value in enumerate(combined_df.columns.values):\n",
        "        worksheet.write(0, col_num, value)\n",
        "        worksheet.set_column(col_num, col_num, 20)\n",
        "    worksheet.autofilter(0, 0, len(combined_df), len(combined_df.columns) - 1)\n",
        "\n",
        "print(f\"Arquivo Excel salvo em: {output_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SuT0q1AIWDAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "flupQFFzWDBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "50PQ_Y86Vp-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJrMpWvYJ7qn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kxm8RYPYaW9-JFfUFSwcvwH0bkw5xhzW",
      "authorship_tag": "ABX9TyPzjHi0FIzcGt8QFuEmIlom",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}